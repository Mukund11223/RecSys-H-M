{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17cfe4b0",
   "metadata": {},
   "source": [
    "# 🛍️ H&M Strong Vanilla Baseline\n",
    "\n",
    "This notebook enhances the baseline model with **Transactions-only** Time-decay + Co-visitation\n",
    "\n",
    "This notebook:\n",
    "- Uses only `transactions_train.csv` and `sample_submission.csv`.\n",
    "- Builds a time-decayed co-visitation matrix (behavior-based, not content).\n",
    "- Uses time-decayed trending items as fallback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6311b36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded\n"
     ]
    }
   ],
   "source": [
    "# Import the libaray\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "from itertools import combinations\n",
    "import math\n",
    "import gc\n",
    "print('Successfully loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14d75e1",
   "metadata": {},
   "source": [
    "### 1) Parameters (tweak for speed / quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300d7d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params set\n"
     ]
    }
   ],
   "source": [
    "# Parameters to control how much data is used and how relevance is calculated\n",
    "LAST_WEEKS = 12      # Keep only last 12 weeks of transactions\n",
    "ALPHA = 1.0          # Time-decay factor in weighting\n",
    "PAIR_DAYS = 14       # Only consider co-visits within 14 days\n",
    "TOPK_COVISIT = 20    # Keep top 20 co-visited items for each item\n",
    "TREND_TOPK = 100     # Number of trending items for fallback\n",
    "\n",
    "print('Params set')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b787a52",
   "metadata": {},
   "source": [
    "### 2) Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf3fa3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading transactions (this may take a while)...\n",
      "Transactions rows: 31788324\n",
      "Sample submission rows: 1371980\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Loading transactions (this may take a while)...')\n",
    "df = pd.read_csv('transactions_train/transactions_train.csv', parse_dates=['t_dat'])\n",
    "sample_sub = pd.read_csv('sample_submission/sample_submission.csv')\n",
    "\n",
    "print('Transactions rows:', len(df))\n",
    "print('Sample submission rows:', len(sample_sub))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555755bf",
   "metadata": {},
   "source": [
    "### 3) Filter recent history for speed & relevance\n",
    "Keeps only the most recent LAST_WEEKS weeks to improve relevance and reduce computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b77fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using transactions from 2020-06-30 to 2020-09-22\n",
      "Filtered transactions rows: 3448116\n"
     ]
    }
   ],
   "source": [
    "# Only keep transactions from the last 12 weeks\n",
    "max_date = df['t_dat'].max()\n",
    "cutoff = max_date - pd.Timedelta(weeks=LAST_WEEKS)\n",
    "df = df[df['t_dat'] >= cutoff].copy().reset_index(drop=True)\n",
    "\n",
    "print('Using transactions from', cutoff.date(), 'to', max_date.date())\n",
    "print('Filtered transactions rows:', len(df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd04a28",
   "metadata": {},
   "source": [
    "## 4) Build time-decayed trending list (fallback)\n",
    "Builds a list of most trending items (recently purchased, weighted by recency) for fallback recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c5793a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top trending (sample): ['0751471001', '0448509014', '0918292001', '0924243001', '0918522001', '0915529003', '0866731001', '0714790020', '0706016001', '0924243002']\n"
     ]
    }
   ],
   "source": [
    "# Calculate days since purchase\n",
    "df['days_diff'] = (max_date - df['t_dat']).dt.days\n",
    "# Apply time decay formula\n",
    "df['time_weight'] = 1.0 / (1.0 + ALPHA * df['days_diff'])\n",
    "\n",
    "# Aggregate scores by article and sort\n",
    "trend_scores = df.groupby('article_id')['time_weight'].sum().sort_values(ascending=False)\n",
    "# Take top trending items (zero-padded)\n",
    "trending_items = [str(x).zfill(10) for x in trend_scores.index[:TREND_TOPK]]\n",
    "\n",
    "print('Top trending (sample):', trending_items[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592646d6",
   "metadata": {},
   "source": [
    "## 5) Build co-visitation\n",
    "Creates a time-decayed item-to-item similarity map from customers’ recent purchases — core of co-visitation recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be84a1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sandeep.palit\\AppData\\Local\\Temp\\ipykernel_23884\\2902697715.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  cust_groups = df.groupby('customer_id').apply(lambda x: list(zip(x['article_id'], x['t_dat'])))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique customers in filtered data: 494132\n",
      "Built co-visitation for 40408 articles\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group purchases by customer\n",
    "cust_groups = df.groupby('customer_id').apply(lambda x: list(zip(x['article_id'], x['t_dat'])))\n",
    "print('Unique customers in filtered data:', len(cust_groups))\n",
    "\n",
    "co_vis = defaultdict(lambda: defaultdict(float))  # co-visitation dictionary\n",
    "\n",
    "for cust, items in cust_groups.items():\n",
    "    # Limit to most recent 50 purchases for that customer\n",
    "    if len(items) > 50:\n",
    "        items = sorted(items, key=lambda x: x[1], reverse=True)[:50]\n",
    "    \n",
    "    # Keep the most recent date per article\n",
    "    art_date = {}\n",
    "    for a, d in items:\n",
    "        if (a not in art_date) or (d > art_date[a]):\n",
    "            art_date[a] = d\n",
    "    \n",
    "    articles = list(art_date.items())\n",
    "    n = len(articles)\n",
    "    if n <= 1:\n",
    "        continue\n",
    "    \n",
    "    # Build item pairs within PAIR_DAYS window\n",
    "    for i in range(n):\n",
    "        a, da = articles[i]\n",
    "        for j in range(i+1, n):\n",
    "            b, db = articles[j]\n",
    "            days = abs((da - db).days)\n",
    "            if days > PAIR_DAYS:\n",
    "                continue\n",
    "            # Time-decayed co-visit weight\n",
    "            w = 1.0 / (1.0 + ALPHA * days)\n",
    "            co_vis[a][b] += w\n",
    "            co_vis[b][a] += w\n",
    "\n",
    "# Keep only top-K neighbors per article\n",
    "co_vis_topk = {}\n",
    "for a, nbrs in co_vis.items():\n",
    "    sorted_n = sorted(nbrs.items(), key=lambda x: -x[1])[:TOPK_COVISIT]\n",
    "    co_vis_topk[a] = [str(int(x[0])).zfill(10) for x in sorted_n]\n",
    "\n",
    "print('Built co-visitation for', len(co_vis_topk), 'articles')\n",
    "\n",
    "# Free memory\n",
    "del co_vis\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfecd2ad",
   "metadata": {},
   "source": [
    "## 6) Prepare recent items per customer\n",
    "Stores each customer’s most recent purchases to start their recommendation list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b405340a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample sizes (first 3 customers): [1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Get recent unique purchases per customer (most recent first)\n",
    "cust_recent = df.sort_values('t_dat', ascending=False).drop_duplicates(subset=['customer_id','article_id'])\n",
    "cust_recent = cust_recent.groupby('customer_id')['article_id'].apply(list).to_dict()\n",
    "\n",
    "# Convert IDs to zero-padded strings for output\n",
    "for k in list(cust_recent.keys())[:3]:\n",
    "    cust_recent[k] = [str(int(x)).zfill(10) for x in cust_recent[k]]\n",
    "\n",
    "print('Sample sizes (first 3 customers):', [len(cust_recent[k]) for k in list(cust_recent.keys())[:3]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8acafa0",
   "metadata": {},
   "source": [
    "## 7) Generate Recommendations\n",
    "Recommendation generation function — uses recent items → co-visitation → trending fallback to compile 12 recommendations per customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91f9b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure co-visitation keys are strings\n",
    "co_vis_topk = {str(int(k)).zfill(10): v for k, v in co_vis_topk.items()}\n",
    "\n",
    "def make_recs_for_customer(cust_id, topk=12):\n",
    "    recs = []\n",
    "    seen = set()\n",
    "    \n",
    "    # 1. Add customer’s own recent purchases\n",
    "    if cust_id in cust_recent:\n",
    "        for a in cust_recent[cust_id]:\n",
    "            if a not in seen:\n",
    "                seen.add(a)\n",
    "                recs.append(a)\n",
    "            if len(recs) == topk:\n",
    "                return recs\n",
    "    \n",
    "    # 2. Add items co-visited with their purchases\n",
    "    if cust_id in cust_recent:\n",
    "        for a in cust_recent[cust_id]:\n",
    "            for nb in co_vis_topk.get(a, []):\n",
    "                if nb not in seen:\n",
    "                    seen.add(nb)\n",
    "                    recs.append(nb)\n",
    "                if len(recs) == topk:\n",
    "                    return recs\n",
    "    \n",
    "    # 3. Add trending items as fallback\n",
    "    for t in trending_items:\n",
    "        if t not in seen:\n",
    "            seen.add(t)\n",
    "            recs.append(t)\n",
    "        if len(recs) == topk:\n",
    "            return recs\n",
    "    \n",
    "    return recs\n",
    "\n",
    "# Generate predictions for all customers\n",
    "cust_list = sample_sub['customer_id'].tolist()\n",
    "preds = []\n",
    "for cust in cust_list:\n",
    "    recs = make_recs_for_customer(cust, topk=12)\n",
    "    # Safety pad if fewer than 12\n",
    "    if len(recs) < 12:\n",
    "        for t in trending_items:\n",
    "            if t not in recs:\n",
    "                recs.append(t)\n",
    "            if len(recs) == 12:\n",
    "                break\n",
    "    preds.append(' '.join(recs[:12]))\n",
    "\n",
    "submission = pd.DataFrame({'customer_id': cust_list, 'prediction': preds})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7293100",
   "metadata": {},
   "source": [
    "## 8) Sanity checks & save submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce0073e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows: 1371980\n",
      "cols: 2\n",
      "header: ['customer_id', 'prediction']\n",
      "min tokens: 12 max tokens: 12\n",
      "All padded correctly? True\n",
      "                                         customer_id  \\\n",
      "0  00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...   \n",
      "1  0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...   \n",
      "2  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...   \n",
      "3  00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...   \n",
      "4  00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...   \n",
      "\n",
      "                                          prediction  \n",
      "0  0568601043 0858856005 0779781015 0762846031 05...  \n",
      "1  0826211002 0824194002 0873217004 0874113004 05...  \n",
      "2  0794321007 0805000001 0794321011 0805000007 07...  \n",
      "3  0751471001 0448509014 0918292001 0924243001 09...  \n",
      "4  0896152002 0791587015 0927530004 0730683050 07...  \n",
      "✅ Submission file saved: strong_vanilla_submission.csv\n"
     ]
    }
   ],
   "source": [
    "print('rows:', submission.shape[0])\n",
    "print('cols:', submission.shape[1])\n",
    "print('header:', submission.columns.tolist())\n",
    "\n",
    "# Ensure predictions have exactly 12 items\n",
    "lengths = submission['prediction'].apply(lambda x: len(x.split()))\n",
    "print('min tokens:', lengths.min(), 'max tokens:', lengths.max())\n",
    "\n",
    "# Check all IDs are zero-padded numeric strings\n",
    "def check_padding(pred):\n",
    "    toks = pred.split()\n",
    "    return all(len(t)==10 and t.isdigit() for t in toks)\n",
    "\n",
    "print('All padded correctly?', submission['prediction'].apply(check_padding).all())\n",
    "\n",
    "print(submission.head())\n",
    "\n",
    "# Save submission\n",
    "submission.to_csv('strong_vanilla_submission.csv', index=False)\n",
    "print(\"Submission file saved: strong_vanilla_submission.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
